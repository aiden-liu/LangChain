{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.llms import OpenAI as OpenAILC\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import SystemMessagePromptTemplate, AIMessagePromptTemplate, ChatPromptTemplate,  HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=client.api_key, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{instruction}\\n{format_instructions}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='List the 5 cities with the hightest populations\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = chat.format_prompt(instruction=\"List the 5 cities with the hightest populations\",\n",
    "                   format_instructions=csv_parser.get_format_instructions()).to_messages()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokyo, Shanghai, Karachi, Beijing, Delhi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply=llm(prompt)\n",
    "reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo', 'Shanghai', 'Karachi', 'Beijing', 'Delhi']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_parser.parse(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(reply.content)\n",
    "# compare with parser's output, this list of chars is not that helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1606-06-03T00:45:55.332436Z, 830-06-15T10:15:37.188538Z, 1230-07-14T04:53:24.192581Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{instruction}\\n{format_instructions}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\"You always give responses with datetime formats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatPromptTemplate.from_messages([system_prompt, human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You always give responses with datetime formats.'),\n",
       " HumanMessage(content=\"The data for when the Netscape browser was launched.\\nWrite a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 479-10-10T18:39:02.462496Z, 2019-06-06T12:33:05.114250Z, 764-10-17T16:13:07.885448Z\\n\\nReturn ONLY this string, no other words!\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = chat.format_prompt(\n",
    "    instruction=\"The data for when the Netscape browser was launched.\",\n",
    "    format_instructions=datetime_parser.get_format_instructions()\n",
    ").to_messages()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1994-12-15T00:00:00.000000Z'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply=llm(prompt)\n",
    "reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1994, 12, 15, 0, 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_parser.parse(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By comparision, let's use datetime package to parse the same string\n",
    "import datetime\n",
    "datetime.datetime.strptime(reply.content, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "# You can achieve the same result if you know the fomat codes in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parser allow people to create their own format of parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Playlist(BaseModel):\n",
    "    name: str = Field(description=\"Name of the playlist\")\n",
    "    songs: list = Field(description=\"A list of songs in the playlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of the playlist\", \"title\": \"Name\", \"type\": \"string\"}, \"songs\": {\"description\": \"A list of songs in the playlist\", \"items\": {}, \"title\": \"Songs\", \"type\": \"array\"}}, \"required\": [\"name\", \"songs\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = \"{instruction}\\n{format_instructions}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_text)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.format_prompt(\n",
    "    instruction=\"Create a playlist for disco songs of 1980s\",\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"name\": \"Disco Hits of the 1980s\",\n",
      "\t\"songs\": [\n",
      "\t\t\"Le Freak - Chic\",\n",
      "\t\t\"Stayin' Alive - Bee Gees\",\n",
      "\t\t\"Super Freak - Rick James\",\n",
      "\t\t\"Funky Town - Lipps Inc.\",\n",
      "\t\t\"Upside Down - Diana Ross\",\n",
      "\t\t\"Boogie Wonderland - Earth, Wind & Fire\",\n",
      "\t\t\"Can't Stop the Music - Village People\",\n",
      "\t\t\"Got to Be Real - Cheryl Lynn\",\n",
      "\t\t\"Last Dance - Donna Summer\",\n",
      "\t\t\"You Should Be Dancing - Bee Gees\"\n",
      "\t]\n",
      "}\n",
      "name='Disco Hits of the 1980s' songs=['Le Freak - Chic', \"Stayin' Alive - Bee Gees\", 'Super Freak - Rick James', 'Funky Town - Lipps Inc.', 'Upside Down - Diana Ross', 'Boogie Wonderland - Earth, Wind & Fire', \"Can't Stop the Music - Village People\", 'Got to Be Real - Cheryl Lynn', 'Last Dance - Donna Summer', 'You Should Be Dancing - Bee Gees']\n"
     ]
    }
   ],
   "source": [
    "reply=llm(prompt)\n",
    "print(reply.content)\n",
    "print(parser.parse(reply.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\n\\t\"name\": \"Disco Hits of the 1980s\",\\n\\t\"songs\": [\\n\\t\\t\"Le Freak - Chic\",\\n\\t\\t\"Stayin\\' Alive - Bee Gees\",\\n\\t\\t\"Super Freak - Rick James\",\\n\\t\\t\"Funky Town - Lipps Inc.\",\\n\\t\\t\"Upside Down - Diana Ross\",\\n\\t\\t\"Boogie Wonderland - Earth, Wind & Fire\",\\n\\t\\t\"Can\\'t Stop the Music - Village People\",\\n\\t\\t\"Got to Be Real - Cheryl Lynn\",\\n\\t\\t\"Last Dance - Donna Summer\",\\n\\t\\t\"You Should Be Dancing - Bee Gees\"\\n\\t]\\n}', response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 205, 'total_tokens': 333}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d65d4260-658a-4f97-ba18-b9f3b0c60788-0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
