{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMRouterChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit complicated than previous chains, just understand the workflow and template.\n",
    "\n",
    "![image](../docs/llm_router_chain_components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### MultiPrompt Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Import chains, router chains and template\n",
    "from langchain.chains import LLMChain, MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router import MultiRouteChain\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_template=\"\"\"You are a very smart human resource persion. \\\n",
    "You are great at answering questions about human resoures in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "law_template=\"\"\"Your are a very smart laywer. \\\n",
    "You are great at answering questions about the law in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        'name': 'human resources',\n",
    "        'description': 'Answer human resources questions',\n",
    "        'template': hr_template\n",
    "    },{\n",
    "        'name': 'law',\n",
    "        'description': 'Answer legal questions',\n",
    "        'template': law_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "\n",
    "for _info in prompt_infos:\n",
    "    name = _info['name']\n",
    "    prompt_template = _info['template']\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm = model, prompt = prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template('{input}')\n",
    "default_chain = LLMChain(llm = model, prompt = default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human resources: Answer human resources questions\n",
      "law: Answer legal questions\n"
     ]
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destination_str = \"\\n\".join(destinations)\n",
    "print(destination_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "human resources: Answer human resources questions\n",
      "law: Answer legal questions\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations = destination_str)\n",
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "law: {'input': 'How do intellectual property laws address the use of AI-generated content?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Intellectual Property (IP) laws as they relate to AI-generated content are complex and rapidly evolving. Currently, there is no international consensus on whether AI-generated content can be protected by copyright. In most jurisdictions, there are two key requirements for copyright protection: originality and human authorship. \\n\\nThe originality requirement is usually met when the work is not copied from another work and embodies the minimal degree of creativity. AI-generated content can arguably meet this requirement.\\n\\nHuman authorship, however, is a more difficult requirement for AI-generated content. In many jurisdictions, copyright protection only extends to works created by humans. \\n\\nIn the United States, for example, the U.S. Copyright Office has declared that it will only register works created by human beings. This means that works created by an AI, without any creative input or intervention from a human, would likely not be eligible for copyright protection.\\n\\nIn the UK, the law is slightly different. Under the UK Copyright, Designs and Patents Act 1988, a computer-generated work can be copyrighted if it is original and the author is taken to be the person \"by whom the arrangements necessary for the creation of the work are undertaken.\"\\n\\nAs you can see, this is a rapidly changing and complex area of law. The legal landscape will likely continue to evolve as AI becomes more sophisticated and its use becomes more widespread. It\\'s also worth noting that the answer could be different depending on the specific type of intellectual property right in question (e.g., patents, trade secrets, etc.)\\n  \\nPlease note, this is a general overview and the specifics can vary greatly depending on the jurisdiction and the particular circumstances. Always consult with a qualified attorney for legal advice.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=['input'],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm=model, prompt=router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain = router_chain,\n",
    "    destination_chains = destination_chains,\n",
    "    default_chain = default_chain,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "chain.run(\"How do intellectual property laws address the use of AI-generated content?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "human resources: {'input': 'How do you handle conflict between team members?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Handling conflict between team members involves several steps:\\n\\n1. Identify the Problem: The first step in resolving any conflict is to understand what the issue is. Talk to each team member involved individually to get their perspective.\\n\\n2. Foster Open Communication: Arrange a meeting with those involved in the conflict. Encourage open and honest communication, where each party can share their side of the story without interruption.\\n\\n3. Find Common Ground: Try to identify any points of agreement, no matter how small. This can help to build a sense of unity and cooperation.\\n\\n4. Develop Solutions: Once the problem is clearly defined, and all parties have had a chance to express their feelings, work with the team members to develop a solution. This should ideally be a compromise that addresses the main concerns of all parties involved.\\n\\n5. Implement and Monitor the Solution: Once a solution has been agreed upon, it should be put into action. Continue to monitor the situation to ensure the conflict does not recur and that the solution is working as intended.\\n\\n6. Provide Training: If conflicts frequently arise, it may be beneficial to provide conflict resolution training for your team.\\n\\nRemember, as an HR professional, maintaining impartiality is crucial throughout this process. If a conflict escalates and cannot be resolved internally, it may be necessary to involve a third-party mediator.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How do you handle conflict between team members?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
