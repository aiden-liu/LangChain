{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain without using LLM, consider such a chain to do the transformation work, like removing sensitive information from a piece of text, etc. Although we can ask LLM to do most of the transformation for us when text is non-sensitive, but still it may cost lots of tokens. Here we can use transformChain to pre-process the text when needed.\n",
    "\n",
    "![image](../docs/steps_of_transform_chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import TransformChain\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean porttitor libero eu tempor vestibulum. Aliquam et pretium ante. In tincidunt risus in pharetra consectetur. Sed a libero eget enim dictum tincidunt. Aliquam justo odio, venenatis sed orci a, bibendum accumsan nisi. Quisque consectetur iaculis leo, eget mattis erat congue et. Nullam pulvinar orci sed maximus tincidunt. Curabitur eget ex consectetur, posuere elit vel, tempor augue. Ut sollicitudin mattis mattis. Mauris ligula est, mattis ut nulla a, bibendum rhoncus velit. Morbi eget tempor turpis, vitae egestas ante. Pellentesque eget erat ac massa convallis aliquam eget id massa. Nulla posuere mi eu ex ornare ornare. Integer sit amet varius lacus.\n",
      "\n",
      "Maecenas suscipit libero et est aliquam, ac bibendum turpis sagittis. Donec ullamcorper neque sem, sit amet lacinia elit vehicula in. Nullam eget lorem non diam auctor semper nec eu odio. Sed in erat eget urna blandit aliquet vel sit amet lectus. Quisque vitae velit lectus. Nullam vitae dui leo. Aenean sollicitudin dolor et sollicitudin ornare. Phasellus consequat congue dolor id pellentesque. Duis dignissim purus magna, eu accumsan erat dapibus vel. Quisque sollicitudin eleifend sem, nec mattis arcu condimentum ac. Nulla et finibus eros, nec fermentum urna. Etiam sodales pellentesque tortor eget mollis. Morbi eleifend, dolor eu sagittis sagittis, est dolor tempus orci, at scelerisque est magna in enim.\n",
      "\n",
      "Aenean sed orci aliquet, mollis massa eget, mattis sapien. Ut nec scelerisque purus. Duis sodales leo elit. Nam auctor ex in dictum tempus. Curabitur mattis, purus eu tempor iaculis, lectus est suscipit erat, ut fermentum nisl nulla id ligula. Duis dapibus a nisi nec consectetur. Maecenas eu leo eu purus dignissim placerat vitae a turpis. Phasellus non consectetur ipsum. Pellentesque quis venenatis nibh.\n",
      "\n",
      "Nullam ac ipsum nec dolor vehicula luctus vitae ac sem. Proin semper et orci a iaculis. Nullam porta mauris ipsum, in suscipit metus blandit ut. Curabitur mollis aliquet erat vitae tempor. Interdum et malesuada fames ac ante ipsum primis in faucibus. Aliquam vehicula mauris sodales risus convallis malesuada. Duis non fermentum nisi, ut pretium est. Sed convallis cursus nunc in placerat. Aenean in nulla mi. Morbi luctus tortor libero, sed aliquam erat posuere non.\n",
      "\n",
      "Etiam volutpat vehicula ligula. Pellentesque at massa sed ex elementum condimentum. Praesent venenatis massa justo. Integer gravida massa iaculis ligula pretium posuere. Sed venenatis porttitor feugiat. Nulla fermentum malesuada lacus, nec bibendum libero interdum a. Etiam ac metus neque. Cras nunc libero, vestibulum a dignissim at, molestie scelerisque nisi. Donec at ex interdum, pretium tellus at, interdum justo. Sed nec neque est. Integer ut erat gravida, scelerisque velit quis, condimentum dui.\n"
     ]
    }
   ],
   "source": [
    "with open(\"../docs/sample_text_lorem_ipsum.txt\", 'r', encoding='utf-8') as file:\n",
    "    sample = file.read()\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Donec ullamcorper neque sem, sit amet lacinia elit vehicula in. Nullam eget lorem non diam auctor semper nec eu odio. Sed in erat eget urna blandit aliquet vel sit amet lectus. Quisque vitae velit lectus. Nullam vitae dui leo. Aenean sollicitudin dolor et sollicitudin ornare. Phasellus consequat congue dolor id pellentesque. Duis dignissim purus magna, eu accumsan erat dapibus vel. Quisque sollicitudin eleifend sem, nec mattis arcu condimentum ac. Nulla et finibus eros, nec fermentum urna. Etiam sodales pellentesque tortor eget mollis. Morbi eleifend, dolor eu sagittis sagittis, est dolor tempus orci, at scelerisque est magna in enim.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def transform (inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    match = re.search(r\"Maecenas suscipit libero et est aliquam, ac bibendum turpis sagittis.(.*?)(?:\\n\\n|$)\", text, re.DOTALL)\n",
    "    section = match.group(1).strip()\n",
    "    return {\"output_text\": section}\n",
    "\n",
    "transform({\"text\": sample})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a transform chain that invoke the above `transform` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"output_text\"],\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a simple template then add them to a sequential chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Summarize this text:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mDonec ullamcorper neque sem, sit amet lacinia elit vehicula in. Nullam eget lorem non diam auctor semper nec eu odio. Sed in erat eget urna blandit aliquet vel sit amet lectus. Quisque vitae velit lectus. Nullam vitae dui leo. Aenean sollicitudin dolor et sollicitudin ornare. Phasellus consequat congue dolor id pellentesque. Duis dignissim purus magna, eu accumsan erat dapibus vel. Quisque sollicitudin eleifend sem, nec mattis arcu condimentum ac. Nulla et finibus eros, nec fermentum urna. Etiam sodales pellentesque tortor eget mollis. Morbi eleifend, dolor eu sagittis sagittis, est dolor tempus orci, at scelerisque est magna in enim.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe text describes a state or condition using intricate and detailed language. It mentions feelings of pain and discomfort, particularly related to certain body parts such as the abdomen, neck, and chest. The text also suggests a sense of magnification or intensification towards the end. However, without specific context, the exact meaning or subject matter is not entirely clear.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The text describes a state or condition using intricate and detailed language. It mentions feelings of pain and discomfort, particularly related to certain body parts such as the abdomen, neck, and chest. The text also suggests a sense of magnification or intensification towards the end. However, without specific context, the exact meaning or subject matter is not entirely clear.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_chain.run(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, so up-till-now, apart from the fact that LLM is super hallucinational and talking non-sense sometimes, you should understand what the TransformChain is about, so further question is: why bother? Why not just call the function and pass its output to LLM, than wrap the function to a TransformChain? \n",
    "\n",
    "Hmmm....interesting....\n",
    "\n",
    "In Chinese, we call it \"Fart after taking off trousers.\" :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
