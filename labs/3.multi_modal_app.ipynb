{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from getpass import getpass\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_llm = ChatOpenAI(\n",
    "    openai_api_key=client.api_key,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    max_tokens=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flan_llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"HuggingFaceTB/SmolLM-135M\", # use a small language model here\n",
    "    model_kwargs={\"max_length\": 100},\n",
    "    timeout=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_process (question):\n",
    "    reply=openai_llm([\n",
    "        SystemMessage(content='You are a helpful assistant in physics.'),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    return reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flan_process(question):\n",
    "    template=\"{question}\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    llm_chain=LLMChain(prompt=prompt, llm=flan_llm)\n",
    "    return llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI reply: A pulsar is a highly magnetized, rotating neutron star that emits beams of electromagnetic radiation out of its magnetic poles. These beams are observed as pulses of radiation at regular intervals as the pulsar rotates. Pulsars are known for their precise and stable rotation rates, making them useful tools for studying a variety of astrophysical phenomena.\n"
     ]
    }
   ],
   "source": [
    "question=input(\"Please enter a prompt: \")\n",
    "\n",
    "openai_reply = openai_process(question)\n",
    "print(\"OpenAI reply: {}\".format(openai_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flan reply: \n",
      "“A pulsar is a very fast spinning neutron star, or black hole, and a neutron star is a very dense and massive star with a very high mass-to-light ratio.”\n",
      "This information was extracted from Wikipedia.\n"
     ]
    }
   ],
   "source": [
    "question=\"What is a pulsar? Explain in less than 100 words.\"\n",
    "flan_reply = flan_process(question)\n",
    "print(\"Flan reply: {}\".format(flan_reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
