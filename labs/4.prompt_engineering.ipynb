{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI as OpenAILC\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=PromptTemplate(input_variables=[], template=\"What is a blackhole?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAILC(\n",
    "    openai_api_key=client.api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A black hole is a region in space where the gravitational pull is so strong that nothing, including light, can escape from it. It is created when a large star dies and its core collapses under its own gravity. The gravitational pull of a black hole is so strong because all of the matter and energy that makes up the star is squeezed into a very small and dense space. The boundary around a black hole from which nothing can escape is called the event horizon. Black holes are invisible as they do not emit or reflect any light, but their presence can be detected by the effect they have on objects and light around them. Objects that get too close to a black hole will be pulled in and crushed by the immense gravitational force.\n"
     ]
    }
   ],
   "source": [
    "print(llm(template.format()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], template='What is a blackhole?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Answer from OpenAI: \n",
      "\n",
      "A round, crunchy, and juicy fruit.\n"
     ]
    }
   ],
   "source": [
    "def describe_template(subject):\n",
    "    prompt = PromptTemplate(input_variables=[\"subject\"],\n",
    "                            template=\"What is {subject} in less than 10 words?\")\n",
    "    return llm(prompt.format(subject=subject))\n",
    "\n",
    "question=input(\"Please input a prompt:\")\n",
    "openai_reply=describe_template(question)\n",
    "print(\"-\"*10)\n",
    "print(\"Answer from OpenAI: {}\".format(openai_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Answer from OpenAI: \n",
      "\n",
      "Yummy fruit for baby to try!\n"
     ]
    }
   ],
   "source": [
    "def describe_template2(subject, tone):\n",
    "    prompt = PromptTemplate(input_variables=[\"subject\", \"tone\"],\n",
    "                            template=\"What is {subject} in less than 10 words? The tone should be {tone}.\")\n",
    "    return llm(prompt.format(subject=subject, tone=tone))\n",
    "\n",
    "question=input(\"Please input a prompt:\")\n",
    "tone=input(\"Please provide a tone:\")\n",
    "openai_reply=describe_template2(question, tone)\n",
    "print(\"-\"*10)\n",
    "print(\"Answer from OpenAI: {}\".format(openai_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import ChatMessage, SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm=ChatOpenAI(openai_api_key=client.api_key, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Reply from OpenAI is: The relationship between pi (π) and the natural constant e is seen in Euler's identity: e^(iπ) + 1 = 0. This elegant formula connects the two fundamental constants of mathematics, highlighting their deep interrelatedness.\n"
     ]
    }
   ],
   "source": [
    "def consult(expertise, question):\n",
    "    system_template=\"You are a consultant that is expert in {expertise}\"\n",
    "    system_message=SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "    human_template=\"{question}\"\n",
    "    human_message=HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt=ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    prompt=chat_prompt.format_prompt(expertise=expertise, question=question).to_messages()\n",
    "    reply=chat_llm(prompt)\n",
    "\n",
    "    return reply.content\n",
    "\n",
    "expertise=input(\"What is the expertise of the robot:\")\n",
    "question=input(\"What's your question:\")\n",
    "openai_reply=consult(expertise=expertise, question=question)\n",
    "print(\"-\"*10)\n",
    "print(\"Reply from OpenAI is: {}\".format(openai_reply))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Reply from OpenAI is: Sheila Jackson Lee is a disaster, always playin' politics and wasting taxpayer money. She's weak on borders and crime, and she doesn't know how to negotiate good deals. Sad!\n"
     ]
    }
   ],
   "source": [
    "def trump_converter(normal_text_input):\n",
    "    template=\"You are an expert in immitating American formal president Donald Trump.\"\n",
    "    system_message=SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    normal_text=\"We shall unite all our allys, both domastic and globally, to battle against the raising threat of third world countries, especially in east Asia.\"\n",
    "    normal_text_tempalte_1=HumanMessagePromptTemplate.from_template(normal_text)\n",
    "\n",
    "    trump_text=\"I hate China, they've taken too many our jobs and import loads of cheat and low quality good into our country. That is not good, we gonna change it.\"\n",
    "    trump_text_template_1=AIMessagePromptTemplate.from_template(trump_text)\n",
    "\n",
    "    normal_text=\"Through our consistant and consolidated effort and after years of dedicated plan, we put Osama bin Laden into justice.\"\n",
    "    normal_text_tempalte_2=HumanMessagePromptTemplate.from_template(normal_text)\n",
    "\n",
    "    trump_text=\"Bin Laden IS died!\"\n",
    "    trump_text_template_2=AIMessagePromptTemplate.from_template(trump_text)\n",
    "\n",
    "    human_template=\"{normal_text_input}\"\n",
    "    human_message=HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt=ChatPromptTemplate.from_messages([system_message, normal_text_tempalte_1, trump_text_template_1, normal_text_tempalte_2, trump_text_template_2, human_message])\n",
    "\n",
    "    reply = chat_llm(chat_prompt.format_prompt(normal_text_input=normal_text_input).to_messages())\n",
    "\n",
    "    return reply.content\n",
    "\n",
    "normal_text_input=input(\"Enter a sentense:\")\n",
    "openai_reply=trump_converter(normal_text_input)\n",
    "print(\"-\"*10)\n",
    "print(\"Reply from OpenAI is: {}\".format(openai_reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
